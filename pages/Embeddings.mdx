## Embeddings
Embeddings是一个多维向量数组，由系列数字组成，它们可以代表任何东西，如文本、音乐、视频等。
![embedding](http://image.iflightit.com/uPic/nevlSK.jpg)
在高层次上，Embeddings是一种将单词表示为向量（数字数组）的方式。每个单词被分配一个浮点数向量，以某种抽象方式表示其含义。Embeddings背后的思想是，含义相近的单词在向量空间中的对应向量之间的距离应更小。例如,“狗”和“猫”都是动物，因此它们的Embeddings在向量空间中应比“苹果”更加接近。
换句话说,通过Embeddings可以获取单词的数值化表示，这些数值表示捕捉了单词之间在语义上和词义上的相关程度。语义相近的单词对应的Embeddings向量也更加相近。所以这种技术常被应用于自然语言处理中，用于评估单词之间的相似度，或者获取词向量用于其他下游任务。
通过为每个单词分配一个实数向量，Embeddings为我们提供了一种简洁的方式来表示词汇表中的每个单词。这些向量旨在编码词义，使得语义相关的单词具有更加相似的Embeddings。因此，我们可以通过计算两个Embeddings之间的距离或相似度来评估这两个单词的相关性。
总的来说，Embeddings提供了一种离散词汇向连续向量空间的映射。这种映射技术对许多自然语言处理任务都很有用。

创建Embedding的过程非常简单，但它依赖具体的Embedding模型（例如：OpenAI 的 Ada）。你将文本发送给模型，模型帮你生成数据的向量结果，可以存储起来后续使用。

Embedding之所以重要，是因为借助Embedding，让我们可以进行语义搜索，也就是通过文本的含义进行相似性检索。在下图的例子中，我们在一个向量空间上表示“男人”、“国王”、“女人”和“王后”，你可以非常容易地看到它们在向量空间之间的关系。
![embedding1](http://image.iflightit.com/uPic/InmPxL.jpg)

还有一个稍微简单一点的例子：想象你是一个孩子，有一个装满玩具的大盒子，现在你想找到一些相似的玩具，比如玩具车和玩具公交车。它们都是交通工具，所以它们是相似的。这就是所谓的“语义相似性”（semantic similarity） - 表示事物之间具有相似的含义/观念。
现在假设你有两个相关的玩具，但不完全一样。比如一个玩具车和一个玩具道路，它们不一样，但还是有相关性，因为汽车通常在道路上行驶。

那么，为什么Embedding如此重要呢？这是因为 LLM（大语言模型）对上下文长度的限制。

在理想的世界里，我们可以在 LLM 的prompt中放入无限数量的单词。但众所周知，现在还做不到，以OpenAI的GPT为例，限制在大约 4096 - 32k 个tokens。所以我们与 LLM 的交互受到长度的限制，因为它的“内存”（能在不超过tokens限制的最大单词数量）。

这就是为什么你不能把一个 PDF 的所有内容复制粘贴到 ChatGPT 中并要求它总结（对于内容不大的PDF现在GPT-4-32k是可以做到的）。

那么怎么把Embedding和LLM关联起来解决tokens长度限制的问题呢？我们可以利用Embedding，在和 LLM 交互时，上下文窗口中仅包含相关的文本内容，这样就不会超过tokens的长度限制。

让我们来看一个例子：假设你有一个巨大的 PDF 文件，也许是一个国会听证会的PDF。你不想完整的阅读整个文件，但你又不能粘贴整个文件给LLM，因为它有成千上万页内容。这就是Embedding的典型应用场景：你可以把 PDF 文件的文本内容先分块，然后借助Embedding把一块块文本变成一个个向量数组，并将其存储在向量数据库中。

在存储分块的向量数组时，通常还需要把向量数组和文本块之间的关系一起保存，这样后面我们按照向量检索出相似的向量数组后，能找出对应的文本块，一个参考的数据结构类似于这样：

> \{ \
    [1,2,3,34]: '文本块1', \
    [2,3,4,56]: '文本块2', \
    [4,5,8,23]: '文本块3', \
    ... \
\}

假如你现在要问对文档提问，“他们对 xyz 说了什么？”

首先，我们先把问题“他们对 xyz 说了什么？”借助Embedding变成向量数组，比如[1,2,3]。

接下来，我们使用相似性搜索将问题向量与我们的PDF的向量进行比较，如果是使用OpenAI的Embedding的话，可以使用余弦相似度。借助相似度检索，现在我们找到3个最相关的向量数组，以及这3个向量数组对应的文本块。

我们现在可以使用这3个文本块，连同prompt一起输入到 LLM 中。例如：
> 已知我们有上下文：文本块1，文本块2，文本块3。\
现在有用户的问题：他们对 xyz 说了什么？ \
请根据给定的上下文，如实回答用户的问题。 \
如果你不能回答，那么如实告诉用户“我不知道” 

LLM 会根据你提供的PDF 中的文本片段，总结整理并如实回答你的问题。这就是将Embedding和 LLM 结合，为文档数据提供聊天问答功能的基本原理解释。也是ChatPDF这类网站的工作原理。

## 参考链接

* [Introducing text and code embeddings](https://openai.com/blog/introducing-text-and-code-embeddings)
* [OpenAI Embedding Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)